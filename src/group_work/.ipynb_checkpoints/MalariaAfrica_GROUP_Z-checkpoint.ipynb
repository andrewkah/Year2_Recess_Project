{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing common libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MalariaAfricaDataset.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-588a8ba5e1e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MalariaAfricaDataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MalariaAfricaDataset.csv'"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "dataset = pd.read_csv(\"MalariaAfricaDataset.csv\")\n",
    "df = pd.DataFrame(dataset)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows and columns\n",
    "number_of_columns = df.shape[1]\n",
    "number_of_rows = df.shape[0]\n",
    "print(f'Number of columns: {number_of_columns}')\n",
    "print(f'Number of rows: {number_of_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting year datatype to datetime\n",
    "df['Year'] = pd.to_datetime(df.Year,format='%Y').dt.year\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "new_column_names = {\n",
    "    'Country Name': 'Country',\n",
    "    'Year': 'Year',\n",
    "    'Country code': 'Country_code',\n",
    "    'Malaria cases reported': 'Reported_cases',\n",
    "    'Incidence of malaria (per 1,000 population at risk)': 'Incidences_per_1000_population_at_risk',\n",
    "    'Intermittent preventive treatment (IPT) of malaria in pregnancy (% of pregnant women)': '%_of_pregnant_women_using_IPT',\n",
    "    'Use of insecticide-treated bed nets (% of under-5 population)': '%_using_IBNs',\n",
    "    'Children with fever receiving antimalarial drugs (% of children under age 5 with fever)': '%_of_children_under_age_5_with_fever',\n",
    "    'Rural population (% of total population)': '%_of_rural_population',\n",
    "    'Urban population (% of total population)': '%_of_urban_population',\n",
    "    'Rural population growth (annual %)': 'annual_%_growth_of_rural_population',\n",
    "    'Urban population growth (annual %)': 'annual_%_growth_of_urban_population',\n",
    "    'People using safely managed sanitation services (% of population)': '%_using_safe_sanity_services',\n",
    "    'People using safely managed sanitation services, urban  (% of urban population)': '%_of_urban_using_safe_sanity_services',\n",
    "    'People using safely managed sanitation services, rural (% of rural population)': '%_of_rural_using_safe_sanity_services',\n",
    "    'People using at least basic sanitation services (% of population)': '%_using_atleast_basic_sanity_services',\n",
    "    'People using at least basic sanitation services, urban  (% of urban population)': '%_of_urban_using_atleast_basic_sanity_services',\n",
    "    'People using at least basic sanitation services, rural (% of rural population)': '%_of_rural_using_atleast_basic_sanity_services',\n",
    "    'People using at least basic drinking water services (% of population)': '%_using_atleast_basic_drinking_water_services',\n",
    "    'People using at least basic drinking water services, urban (% of urban population)': '%_of_urban_using_atleast_basic_drinking_water_services',\n",
    "    'People using at least basic drinking water services, rural (% of rural population)': '%_of_rural_using_atleast_basic_drinking_water_services',\n",
    "    'People using safely managed drinking water services (% of population)': '%_using_safe_drinking_water_services',\n",
    "    'People using safely managed drinking water services, urban (% of urban population)': '%_of_urban_using_safe_drinking_water_services',\n",
    "    'People using safely managed drinking water services, rural (% of rural population)': '%_of_rural_using_safe_drinking_water_services',\n",
    "    'longitude': 'longitude',\n",
    "    'latitude': 'latitude',\n",
    "    'geometry': 'geometry'\n",
    "}\n",
    "\n",
    "df.rename(columns=new_column_names, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review changes\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of missing values per column in descending order\n",
    "number_of_missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "number_of_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of null values per column in descending order\n",
    "percentage_of_missing_values = (df.isnull().sum()/df.shape[0]*100).sort_values(ascending=False)\n",
    "percentage_of_missing_values = percentage_of_missing_values.apply(lambda x: f'{x:.2f}%')\n",
    "percentage_of_missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for rows where the sum of '%_of_rural_population' and '%_of_urban_population' is not equal to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain sum of %_of_rural_population and %_of_urban_population\n",
    "df['%_of_total_population'] = df[['%_of_rural_population', '%_of_urban_population']].sum(axis=1)\n",
    "# Checking for rows where %_of_rural_population + %_of_urban_population is not equal to 100\n",
    "invalid_total_population = df[(df['%_of_rural_population'].notnull()) & (df['%_of_urban_population'].notnull()) &\n",
    "                             (df['%_of_rural_population'] + df['%_of_urban_population'] != 100)].reset_index(drop=True)\n",
    "\n",
    "print(f'Number of such rows: {invalid_total_population.shape[0]}')\n",
    "    \n",
    "invalid_total_population[['Country', 'Year', '%_of_rural_population', '%_of_urban_population', '%_of_total_population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm to normalize the '%_of_rural_population' and '%_of_urban_population' columns for rows where the sum is not 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to normalize %_of_rural_population and %_of_urban_population where the total population percentage is not 100\n",
    "def normalize_percentages(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notnull(row['%_of_rural_population']) and pd.notnull(row['%_of_urban_population']) and \\\n",
    "                (row['%_of_rural_population'] + row['%_of_urban_population'] != 100):\n",
    "            # Calculate normalized values\n",
    "            normalized_rural_percentage = (row['%_of_rural_population'] / (row['%_of_rural_population'] + row['%_of_urban_population'])) * 100\n",
    "            normalized_urban_percentage = (row['%_of_urban_population'] / (row['%_of_rural_population'] + row['%_of_urban_population'])) * 100\n",
    "            # Round to 2 decimal places\n",
    "            normalized_rural_percentage = round(normalized_rural_percentage, 2)\n",
    "            normalized_urban_percentage = round(normalized_urban_percentage, 2)\n",
    "            # Assign the values to new columns\n",
    "            df.at[index, '%_of_rural_population'] = normalized_rural_percentage\n",
    "            df.at[index, '%_of_urban_population'] = normalized_urban_percentage\n",
    "    return df\n",
    "\n",
    "df = normalize_percentages(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review normalization results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for rows where %_of_rural_population + %_of_urban_population is not equal to 100\n",
    "new_invalid_total_population = df[(df['%_of_rural_population'].notnull()) & (df['%_of_urban_population'].notnull()) &\n",
    "                             (df['%_of_rural_population'] + df['%_of_urban_population'] != 100)].reset_index(drop=True)\n",
    "\n",
    "print(f'Number of such rows: {new_invalid_total_population.shape[0]}')\n",
    "    \n",
    "new_invalid_total_population[['Country', 'Year', '%_of_rural_population', '%_of_urban_population', '%_of_total_population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill cells where values are \"Missing At Random\", which means that their values can be determined using values from other columns.\n",
    "\n",
    "The algorithm is based off of four equations which represent a mathematical relationship between some of the columns as shown below.\n",
    "1. %_using_safe_sanity_services = (%_of_rural_using_safe_sanity_services * %_of_rural_population) + (%_of_urban_using_safe_sanity_services * %_of_urban_population)/100\n",
    "\n",
    "2. %_using_atleast_basic_drinking_water_services = (%_of_rural_using_atleast_basic_drinking_water_services * %_of_rural_population) + (%_of_urban_using_atleast_basic_drinking_water_services * %_of_urban_population)/100\n",
    "\n",
    "3. %_using_atleast_basic_sanity_services = (%_of_rural_using_atleast_basic_sanity_services * %_of_rural_population) + (%_of_urban_using_atleast_basic_sanity_services * %_of_urban_population)/100\n",
    "\n",
    "4. %_using_safe_drinking_water_services = (%_of_rural_using_safe_drinking_water_services * %_of_rural_population) + (%_of_urban_using_safe_drinking_water_services * %_of_urban_population)/100\n",
    "\n",
    "Eritrea is the only country with null values in the '%_of_rural_population' and '%_of_urban_population' columns, which can be calculated using values provided in the columns '%_using_atleast_basic_sanity_services', '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services', '%_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_drinking_water_services', and '%_of_urban_using_atleast_basic_drinking_water_services'\n",
    "\n",
    "Eritrea is also the only contry with null values in the 'annual_&#37;\\_growth_of_rural_population' and 'annual\\_&#37;_growth_of_urban_population' columns\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain rows where the country is Eritrea\n",
    "eritrea = df[df['Country'] == 'Eritrea'].reset_index(drop=True)\n",
    "# Display population percentages\n",
    "eritrea[['Country', 'Year', '%_of_rural_population', '%_of_urban_population', 'annual_%_growth_of_rural_population', 'annual_%_growth_of_urban_population']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithm to fill the %_of_rural_population and %_of_urban_population columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_missing_percentage_population(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notnull(row['%_using_atleast_basic_drinking_water_services']) and pd.notnull(row['%_of_rural_using_atleast_basic_drinking_water_services']) \\\n",
    "            and pd.notnull(row['%_of_urban_using_atleast_basic_drinking_water_services']) and pd.notnull(row['%_using_atleast_basic_sanity_services']) \\\n",
    "            and pd.notnull(row['%_of_rural_using_atleast_basic_sanity_services']) and pd.notnull(row['%_of_urban_using_atleast_basic_sanity_services']) and \\\n",
    "            pd.isnull(row['%_of_rural_population']) and pd.isnull(row['%_of_urban_population']):\n",
    "\n",
    "            coefficients = [[row['%_of_rural_using_atleast_basic_drinking_water_services']/100, row['%_of_urban_using_atleast_basic_drinking_water_services']/100],\n",
    "                                     [row['%_of_rural_using_atleast_basic_sanity_services']/100, row['%_of_urban_using_atleast_basic_sanity_services']/100]]\n",
    "            constants = [row['%_using_atleast_basic_drinking_water_services'], row['%_using_atleast_basic_sanity_services']]\n",
    "            \n",
    "            try:\n",
    "                # Try to solve the system using the regular solve() function\n",
    "                solution = np.linalg.solve(coefficients, constants)\n",
    "                rural_population_percentage = float(format(solution[0], '.2f'))\n",
    "                urban_population_percentage = float(format(solution[1], '.2f'))\n",
    "\n",
    "            except np.linalg.LinAlgError as e:\n",
    "                # If the matrix is singular, use the inverse instead\n",
    "                print(f\"Warning: {e}\")\n",
    "                inverse = np.linalg.pinv(coefficients)\n",
    "                solution = np.dot(inverse, constants)\n",
    "                rural_population_percentage = float(format(solution[0], '.2f'))\n",
    "                urban_population_percentage = float(format(solution[1], '.2f'))\n",
    "\n",
    "            if (rural_population_percentage + urban_population_percentage) != 100:\n",
    "                 # Calculate normalized values\n",
    "                normalized_rural_percentage = (rural_population_percentage / (rural_population_percentage + urban_population_percentage)) * 100\n",
    "                normalized_urban_percentage = (urban_population_percentage / (rural_population_percentage + urban_population_percentage)) * 100\n",
    "                # Round to 2 decimal places\n",
    "                normalized_rural_percentage = round(normalized_rural_percentage, 2)\n",
    "                normalized_urban_percentage = round(normalized_urban_percentage, 2)\n",
    "                # Assign the values to new columns\n",
    "                df.at[index, '%_of_rural_population'] = normalized_rural_percentage\n",
    "                df.at[index, '%_of_urban_population'] = normalized_urban_percentage\n",
    "            else:\n",
    "                df.at[index, '%_of_rural_population'] = rural_population_percentage\n",
    "                df.at[index, '%_of_urban_population'] = urban_population_percentage\n",
    "        \n",
    "        # For rows with no values for '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services',\n",
    "        # '%_of_rural_using_atleast_basic_sanity_services', and '%_of_urban_using_atleast_basic_sanity_services' insert 0's because they can't be calculated\n",
    "        if pd.notnull(row['%_using_atleast_basic_drinking_water_services']) and pd.isnull(row['%_of_rural_using_atleast_basic_drinking_water_services']) \\\n",
    "            and pd.isnull(row['%_of_urban_using_atleast_basic_drinking_water_services']) and pd.notnull(row['%_using_atleast_basic_sanity_services']) \\\n",
    "            and pd.isnull(row['%_of_rural_using_atleast_basic_sanity_services']) and pd.isnull(row['%_of_urban_using_atleast_basic_sanity_services']) and \\\n",
    "            pd.notnull(row['%_of_rural_population']) and pd.notnull(row['%_of_urban_population']):\n",
    "\n",
    "            df.at[index, '%_of_rural_using_atleast_basic_drinking_water_services'] = 0.00\n",
    "            df.at[index, '%_of_urban_using_atleast_basic_drinking_water_services'] = 0.00\n",
    "            df.at[index, '%_of_rural_using_atleast_basic_sanity_services'] = 0.00\n",
    "            df.at[index, '%_of_urban_using_atleast_basic_sanity_services'] = 0.00\n",
    "\n",
    "    return df        \n",
    "\n",
    "            \n",
    "df = fill_missing_percentage_population(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that '%_of_rural_population' and '%_of_urban_population' have been filled.\n",
    "\n",
    "The last row, however, still has null values because '%_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services', '%_using_atleast_basic_sanity_services', '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services' are null and yet these are the values required by the algorithm to calculate the '%_of_rural_population' and '%_of_urban_population'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain rows where the country is Eritrea\n",
    "eritrea = df[df['Country'] == 'Eritrea'].reset_index(drop=True)\n",
    "# Display population percentages\n",
    "print(\"One row still has null values for '%_of_rural_population' and '%_of_urban_population' because the columns whose values are used to calculate them were null\")\n",
    "eritrea[['Country', 'Year', '%_of_rural_population', '%_of_urban_population', 'annual_%_growth_of_rural_population', 'annual_%_growth_of_urban_population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We realised that we are working with time-series data, which means that the data contains trends or patterns which are clearly visible to the naked eye.\n",
    "\n",
    "Mean and mode imputation were therefore not an option because they would introduce biases and affect existing trends or patterns.\n",
    "\n",
    "We developed an algorithm that utilises regression, to predict and fill the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = df.columns\n",
    "def fill_with_regression(original_dataframe, new_dataframe, target_column, feature_column):\n",
    "    # Filter rows with available data to train the model\n",
    "    df_train = new_dataframe.dropna(subset=[target_column])\n",
    "\n",
    "    # Create a linear regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Fit the model\n",
    "    X_train = df_train[feature_column].to_numpy().reshape(-1, 1)\n",
    "    y_train = df_train[target_column].to_numpy()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the missing values\n",
    "    X_pred = new_dataframe[new_dataframe[target_column].isnull()][feature_column].to_numpy().reshape(-1, 1)\n",
    "    y_pred = model.predict(X_pred)\n",
    "\n",
    "    # Update the DataFrame with the rounded predicted values\n",
    "    new_dataframe.loc[new_dataframe[target_column].isnull(), target_column] = y_pred\n",
    "\n",
    "    # Round off to 2 decimal places\n",
    "    new_dataframe[target_column] = new_dataframe[target_column].round(2)\n",
    "\n",
    "    # merging the original dataframe with the dataframe containing filled in values \n",
    "    merged_df = pd.merge(original_dataframe, new_dataframe, on=['Country', \"Country Code\", 'Year'], how='left')\n",
    "\n",
    "    exclude_columns = ['Country', 'Year', 'Country Code']\n",
    "\n",
    "    for column in all_columns:\n",
    "        if column not in exclude_columns:\n",
    "            # Add data from the eritrea dataframe where it is missing in the original dataframe\n",
    "            merged_df[column] = np.where(\n",
    "            (merged_df[column + '_x'].isnull()) &\n",
    "            (~merged_df[column + '_y'].isnull()),\n",
    "            merged_df[column + '_y'],\n",
    "            merged_df[column + '_x']\n",
    "            )\n",
    "            # Delete the unnecessary columns\n",
    "            merged_df = merged_df.drop([column + '_x', column + '_y'], axis=1)\n",
    "\n",
    "    # Calculate MSE and R-squared for the model\n",
    "    mse = round(mean_squared_error(y_train, model.predict(X_train)), 2)\n",
    "    r_squared = round(r2_score(y_train, model.predict(X_train)), 2)\n",
    "\n",
    "    return merged_df, mse, r_squared, target_column\n",
    "\n",
    "eritrea_columns = ['%_of_rural_population', '%_of_urban_population','annual_%_growth_of_rural_population', 'annual_%_growth_of_urban_population']\n",
    "\n",
    "for column in eritrea_columns:\n",
    "    df, mse, r_squared, target_column = fill_with_regression(df, eritrea, column, 'Year')\n",
    "    print(f'The Mean Squared Error for the model used to predict {target_column} values is: {mse}')\n",
    "    print(f'The r_squared for the model used to predict {target_column} values is: {r_squared}')\n",
    "    print(\"\")\n",
    "\n",
    "print('All missing values have been filled')\n",
    "\n",
    "eritrea[['Country', 'Year', '%_of_rural_population', '%_of_urban_population', 'annual_%_growth_of_rural_population', 'annual_%_growth_of_urban_population']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values for '%\\_of_rural_population', '%\\_of_rural_population', 'annual_%\\_growth_of_rural_population' and 'annual\\_%_growth_of_urban_population' have been filled.\n",
    "\n",
    "We then went ahead to fill missing values for '%\\_of_urban_using_atleast_basic_sanity_services', '%\\_of_rural_using_atleast_basic_drinking_water_services', '%\\_of_urban_using_atleast_basic_drinking_water_services', '%\\_of_rural_using_atleast_basic_sanity_services', '%_using_atleast_basic_drinking_water_services', '%_using_atleast_basic_sanity_services'   \n",
    "\n",
    "South Sudan, Eritrea and Central African Republic have rows with no data for these columns.\n",
    "\n",
    "We again noticed trends in this data and therefore, regression imputation was used.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "South_Sudan = df[df['Country'] == \"South Sudan\"]\n",
    "South_Sudan[['Country', '%_using_atleast_basic_sanity_services', '%_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "null_columns = ['%_using_atleast_basic_drinking_water_services', '%_using_atleast_basic_sanity_services', '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services',\n",
    "               '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services']\n",
    "for column in null_columns:\n",
    "    df, mse, r_squared, target_column = fill_with_regression(df, South_Sudan, column, 'Year')\n",
    "    print(f'The Mean Squared Error for the model used to predict {target_column} values is: {mse}')\n",
    "    print(f'The r_squared for the model used to predict {target_column} values is: {r_squared}')\n",
    "    print('')\n",
    "\n",
    "print(\"All specified columns with missing values have been filled \")\n",
    "\n",
    "South_Sudan[['Country', '%_using_atleast_basic_sanity_services', '%_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services', \n",
    "             '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain rows where the country is Eritrea\n",
    "eritrea = df[df['Country'] == 'Eritrea'].reset_index(drop=True)\n",
    "# Display population percentages\n",
    "print(\"One row has null values for these columns\")\n",
    "eritrea[['Country', 'Year', '%_using_atleast_basic_sanity_services', '%_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services',\n",
    "          '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in null_columns:\n",
    "    df, mse, r_squared, target_column = fill_with_regression(df, eritrea, column, 'Year')\n",
    "    print(f'The Mean Squared Error for the model used to predict {target_column} values is: {mse}')\n",
    "    print(f'The r_squared for the model used to predict {target_column} values is: {r_squared}')\n",
    "    print('')\n",
    "    \n",
    "print(\"All specified columns with missing values have been filled using regression\")\n",
    "\n",
    "eritrea[['Country', '%_using_atleast_basic_sanity_services', '%_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services', \n",
    "             '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "central_african_republic = df[df['Country'] == 'Central African Republic'].reset_index(drop=True)\n",
    "# Display population percentages\n",
    "print(\"One row has null values for these columns\")\n",
    "central_african_republic[['Country', 'Year', '%_using_atleast_basic_sanity_services', '%_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services',\n",
    "          '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in null_columns:\n",
    "    df, mse, r_squared, target_column = fill_with_regression(df, central_african_republic, column, 'Year')\n",
    "    print(f'The Mean Squared Error for the model used to predict {target_column} values is: {mse}')\n",
    "    print(f'The r_squared for the model used to predict {target_column} values is: {r_squared}')\n",
    "    print('')\n",
    "    \n",
    "print(\"All specified columns with missing values have been filled using regression\")\n",
    "\n",
    "central_african_republic[['Country', '%_using_atleast_basic_sanity_services', '%_using_atleast_basic_drinking_water_services', '%_of_rural_using_atleast_basic_drinking_water_services', '%_of_urban_using_atleast_basic_drinking_water_services', \n",
    "             '%_of_rural_using_atleast_basic_sanity_services', '%_of_urban_using_atleast_basic_sanity_services']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped the columns, '%_of_rural_using_safe_drinking_water_services', '%_of_urban_using_safe_drinking_water_services', '%_using_safe_sanity_services', '%_of_rural_using_safe_sanity_services', '%_of_urban_using_safe_sanity_services' because of the reasons below.\n",
    "\n",
    "1. They have a very high percentage of missing values. This being time-series data(data with patterns or trends), most if not all of the possible imputation methods were not applicable. Regression imputation was not possible because there was no tangible amount of data to train the models and mean or mode imputation would affect underlying trends and introduce bias.\n",
    "\n",
    "2. According to \"World Bank Open Data website\", The percentage of people using at least basic services encompasses both people using basic services as well as those using safely managed services. We then based our analysis on columns with \"People using atleast basic services\" to avoid redundancy in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['%_of_rural_using_safe_drinking_water_services', '%_of_urban_using_safe_drinking_water_services', '%_using_safe_sanity_services', \n",
    "                   '%_of_rural_using_safe_sanity_services', '%_of_urban_using_safe_sanity_services', '%_using_safe_drinking_water_services']\n",
    "\n",
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill missing values for 'Incidences_per_1000_population_at_risk', 'Reported_cases'.\n",
    "\n",
    "Tunisia,  Mauritius, Lesotho and Libya have no data for these columns. \n",
    "\n",
    "We filled these missing values with 0's because mean, mode or regression imputation were not applicable. Using other countries data to fill missing values for \"Incidences_per_1000_population_at_risk\" and \"Reported_cases\" for another country was not logical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values in the specified columns with 0\n",
    "columns_to_fill = ['Incidences_per_1000_population_at_risk', 'Reported_cases']\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling missing values for '%_using_IBNs', '%_of_children_under_age_5_with_fever', '%_of_pregnant_women_using_IPT'\n",
    "\n",
    "Filling one country's missing values using data from other countries was not logical. \n",
    "\n",
    "Therefore, we grouped each countries rows into a single dataframe, calculated the mean for each column and used it to fill the missing values.\n",
    "\n",
    "For countries with no values for each of the three columns, the missing values were replaced with 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['%_using_IBNs', '%_of_children_under_age_5_with_fever', '%_of_pregnant_women_using_IPT']\n",
    "for col in columns_of_interest:\n",
    "    df[col] = df[col].fillna(df.groupby('Country')[col].transform('mean'))\n",
    "    df[col] = df[col].round(2)\n",
    "    \n",
    "# Replace NaN with 0 after filling missing values\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirming whether all columns have been filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_null_values = (df.isnull().sum()/df.shape[0]*100).sort_values(ascending=False)\n",
    "percentage_of_null_values = percentage_of_null_values.apply(lambda x: f'{x:.2f}%')\n",
    "percentage_of_null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig1 = px.choropleth(df,\n",
    "                     locations=df['Country Code'],\n",
    "                     color=df['Incidences_per_1000_population_at_risk'],\n",
    "                     color_continuous_scale='Blues',\n",
    "                     locationmode='ISO-3',scope='africa',\n",
    "                     animation_frame=df['Year'],\n",
    "                     title=\"Incidence of Malaria at risk in Africa\",\n",
    "                     labels={'color':'Incidence of Malaria'})\n",
    "\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.line(df, x='Year', y='Incidences_per_1000_population_at_risk', \n",
    "               color='Country', title='Trend of Malaria Incidences over the Years',\n",
    "               labels={'Year': 'Year', 'Incidences_per_1000_population_at_risk': 'Malaria Incidences'})\n",
    "\n",
    "# Show the plot\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create a histogram for the 'Incidences_per_1000_population_at_risk' variable\n",
    "fig1 = px.histogram(df, x='Incidences_per_1000_population_at_risk', nbins=20,\n",
    "                    title='Distribution of Malaria Incidences per 1000 Population at Risk')\n",
    "fig1.show()\n",
    "\n",
    "# Create a histogram for the '%_using_IBNs' variable\n",
    "fig2 = px.histogram(df, x='%_using_IBNs', nbins=20,\n",
    "                    title='Distribution of Percentage of People Using Insecticide-Treated Bed Nets')\n",
    "fig2.show()\n",
    "\n",
    "# Create a histogram for the '%_of_rural_population' variable\n",
    "fig3 = px.histogram(df, x='%_of_rural_population', nbins=20,\n",
    "                    title='Distribution of Percentage of Rural Population')\n",
    "fig3.show()\n",
    "\n",
    "# Add more histograms for other variables as needed...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_incidences_by_year = df.groupby('Year')['Incidences_per_1000_population_at_risk'].mean().reset_index()\n",
    "\n",
    "# Create a line plot to visualize the trend of average malaria incidences over the years\n",
    "fig3 = px.line(average_incidences_by_year, x='Year', y='Incidences_per_1000_population_at_risk',\n",
    "               title='Trend of Average Malaria Incidences over the Years',\n",
    "               labels={'Year': 'Year', 'Incidences_per_1000_population_at_risk': 'Average Malaria Incidences'})\n",
    "\n",
    "# Show the plot\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Select the relevant columns for the correlation analysis\n",
    "correlation_df = df[['%_using_IBNs', 'Incidences_per_1000_population_at_risk']]\n",
    "\n",
    "# Compute the correlation coefficient (Pearson correlation)\n",
    "correlation_coefficient = correlation_df.corr().iloc[0, 1]\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Correlation Coefficient:\", correlation_coefficient)\n",
    "\n",
    "# Visualize the relationship with a scatter plot\n",
    "plt.scatter(correlation_df['%_using_IBNs'], correlation_df['Incidences_per_1000_population_at_risk'])\n",
    "plt.xlabel('% of People Using Insecticide-Treated Bed Nets')\n",
    "plt.ylabel('Malaria Incidences per 1000 Population at Risk')\n",
    "plt.title('Correlation between Use of Insecticide-Treated Bed Nets and Malaria Incidences')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing spaces from column name\n",
    "correlation_df = df[['%_of_rural_using_atleast_basic_drinking_water_services', 'Incidences_per_1000_population_at_risk']]\n",
    "\n",
    "# Compute the correlation coefficient (Pearson correlation)\n",
    "correlation_coefficient = correlation_df.corr().iloc[0, 1]\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Correlation Coefficient:\", correlation_coefficient)\n",
    "\n",
    "# Visualize the relationship with a scatter plot\n",
    "plt.scatter(correlation_df['%_of_rural_using_atleast_basic_drinking_water_services'], correlation_df['Incidences_per_1000_population_at_risk'])\n",
    "plt.xlabel('% of People Using Safely Managed Drinking Water Services (Rural)')\n",
    "plt.ylabel('Malaria Incidences per 1000 Population at Risk')\n",
    "plt.title('Correlation between Access to Safe Drinking Water Services (Rural) and Malaria Incidences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Boxplot for \"Incidences_per_1000_population_at_risk\" across different years\n",
    "fig_year = px.box(df, x='Year', y='Incidences_per_1000_population_at_risk',\n",
    "                  title='Boxplot of Malaria Incidences per 1000 Population at Risk Across Years')\n",
    "fig_year.show()\n",
    "\n",
    "# Boxplot for \"Incidences_per_1000_population_at_risk\" across different countries\n",
    "fig_country = px.box(df, x='Country', y='Incidences_per_1000_population_at_risk',\n",
    "                     title='Boxplot of Malaria Incidences per 1000 Population at Risk Across Countries')\n",
    "fig_country.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create a scatter plot to explore the relationship between annual growth rates of rural and urban populations\n",
    "fig = px.scatter(df, x='annual_%_growth_of_rural_population', y='annual_%_growth_of_urban_population',\n",
    "                 title='Relationship between Annual Growth Rates of Rural and Urban Populations',\n",
    "                 labels={'annual_%_growth_of_rural_population': 'Annual Growth Rate of Rural Population',\n",
    "                         'annual_%_growth_of_urban_population': 'Annual Growth Rate of Urban Population'})\n",
    "\n",
    "# Show the scatter plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Define the independent variable (X) and dependent variable (y)\n",
    "X = df['annual_%_growth_of_rural_population']\n",
    "y = df['annual_%_growth_of_urban_population']\n",
    "\n",
    "# Add a constant term to the independent variable (X) for the intercept term in the regression model\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the summary of the regression model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Investigate whether access to basic drinking water services is associated with the incidence of malaria.\")\n",
    "correlation_df = df[['%_using_atleast_basic_drinking_water_services', 'Incidences_per_1000_population_at_risk']]\n",
    "\n",
    "# Compute the correlation coefficient (Pearson correlation)\n",
    "correlation_coefficient = correlation_df.corr().iloc[0, 1]\n",
    "\n",
    "print(\"Correlation Coefficient:\", correlation_coefficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "# Select the relevant columns for the correlation analysis\n",
    "correlation_df_rural = df[['%_of_rural_using_atleast_basic_drinking_water_services', 'Incidences_per_1000_population_at_risk']]\n",
    "\n",
    "# Compute the correlation coefficient (Pearson correlation) for rural areas\n",
    "correlation_coefficient_rural = correlation_df_rural.corr().iloc[0, 1]\n",
    "\n",
    "print(\"Correlation Coefficient (Rural):\", correlation_coefficient_rural)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Separate the data for rural areas with access and without access to basic drinking water services\n",
    "rural_with_access = df[df['%_of_rural_using_atleast_basic_drinking_water_services'] > 0]\n",
    "rural_without_access = df[df['%_of_rural_using_atleast_basic_drinking_water_services'] == 0]\n",
    "\n",
    "# Extract the incidence data for the two groups\n",
    "incidences_with_access = rural_with_access['Incidences_per_1000_population_at_risk']\n",
    "incidences_without_access = rural_without_access['Incidences_per_1000_population_at_risk']\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "statistic, p_value = mannwhitneyu(incidences_with_access, incidences_without_access, alternative='two-sided')\n",
    "\n",
    "print(\"Mann-Whitney U Statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
